{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red120\green193\blue99;
\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c1\c1;\cssrgb\c100000\c100000\c99985\c0;\cssrgb\c53553\c79021\c46469;
\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Outils et technologies utilis\'e9es:\
Python\
Numpy\
Pandas\
Matplotlib\
Scikit Learn\
Tensorflow\
Google Colab\
Jupyter\
Anaconda\
Streamlit\
Google Drive\
VS Code\
\
\
\
PS1: We shouldn\'92t forget screenshots from visualisation for the presentation de la soutenance\
\
PS2: 
\f1 \cf2 \cb3 \expnd0\expndtw0\kerning0
Recall literally is how many of the true positives were recalled (found), i.e. how many of the correct hits were also found. Precision (your formula is incorrect) is how many of the returned hits were true positive i.e. how many of the found were correct hits.\
\
PS3: Install the used libraries to make the solution work\cf5 \cb1 \
}